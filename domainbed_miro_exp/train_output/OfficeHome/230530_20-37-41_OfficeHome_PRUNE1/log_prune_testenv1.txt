[37m[36mINFO[0m[0m 05/30 20:37:41 | Command :: prune_all.py OfficeHome_PRUNE1 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 1 --model_save 0 --steps 4000
Environment:
	Python: 3.8.5
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.22.4
	PIL: 9.2.0
Args:
	algorithm: MIRO
	checkpoint_freq: None
	configs: []
	data_dir: ../domain_bed
	dataset: OfficeHome
	debug: False
	deterministic: True
	evalmode: fast
	holdout_fraction: 0.2
	model_save: 0
	name: OfficeHome_PRUNE1
	out_dir: train_output/OfficeHome/230530_20-37-41_OfficeHome_PRUNE1
	out_root: train_output/OfficeHome
	prebuild_loader: False
	prune_method: uni
	seed: 0
	show: False
	steps: 4000
	tb_freq: 10
	test_envs: None
	testenv: 1
	trial_seed: 0
	unique_name: 230530_20-37-41_OfficeHome_PRUNE1
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	[36mresnet_dropout: 0.1
	[0mclass_balanced: False
	optimizer: adam
	freeze_bn: True
	pretrained: True
	[36mlr: 6e-06
	[0mbatch_size: 32
	[36mweight_decay: 1e-06
	[0mswad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	[36mld: 0.1
	[0mlr_mult: 10.0
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: Art (#2427)
	env1: Clipart (#4365)
	env2: Product (#4439)
	env3: Real World (#4357)

[37m[36mINFO[0m[0m 05/30 20:37:41 | n_steps = 4000
[37m[36mINFO[0m[0m 05/30 20:37:41 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 05/30 20:37:41 | n_steps is updated to 4000 => 4001 for checkpointing
[37m[36mINFO[0m[0m 05/30 20:37:41 | Target test envs = [[0], [1], [2], [3]]
[37m[36mINFO[0m[0m 05/30 20:37:41 | Prune and finetune for test environment 1
[37m[36mINFO[0m[0m 05/30 20:37:41 | 
[37m[36mINFO[0m[0m 05/30 20:37:41 | Testenv name escaping te_Clipart -> te_Clipart
[37m[36mINFO[0m[0m 05/30 20:37:41 | Test envs = [1], name = te_Clipart
[37m[36mINFO[0m[0m 05/30 20:37:41 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 05/30 20:37:41 | steps-per-epoch for each domain: 60.69, 111.00, 108.94 -> min = 60.69
[37m[36mINFO[0m[0m 05/30 20:38:00 | 23454912.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:38:42 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_in     env1_out    env2_out    env3_out   
[37m[36mINFO[0m[0m 05/30 20:38:42 | 0.547824    0.518900    0.000000    0.869091    0.528254    0.810309    0.547824    0.518900    0.927847    0.869116   
[37m[36mINFO[0m[0m 05/30 20:38:42 | Pruning Completed
[37m[36mINFO[0m[0m 05/30 20:38:42 | 22314688.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:38:42 | # of params = 47153153
[37m[36mINFO[0m[0m 05/30 20:39:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_in     env1_out    env2_out    env3_out    step        epoch       loss        reg_loss    step_time   eval_time  
[37m[36mINFO[0m[0m 05/30 20:39:25 | 0.512314    0.508591    0.000000    0.793413    0.832552    0.715464    0.512314    0.508591    0.873732    0.791045    0           0.000000    -0.268862   -6.632516   0.712754    42.835429  
[37m[36mINFO[0m[0m 05/30 20:42:21 | 0.569015    0.545246    0.000000    0.859820    0.562207    0.804124    0.569015    0.545246    0.917700    0.857635    200         3.295572    -0.588994   -6.613524   0.659108    44.281369  
[37m[36mINFO[0m[0m 05/30 20:45:22 | 0.567010    0.536082    0.000000    0.856285    0.549683    0.785567    0.567010    0.536082    0.922210    0.861079    400         6.591143    -0.644507   -6.790180   0.686289    43.545139  
[37m[36mINFO[0m[0m 05/30 20:48:26 | 0.567869    0.528064    0.000000    0.860466    0.542740    0.795876    0.567869    0.528064    0.925592    0.859931    600         9.886715    -0.660475   -6.879092   0.679051    48.352875  
[37m[36mINFO[0m[0m 05/30 20:51:30 | 0.563001    0.539519    0.000000    0.863904    0.549577    0.795876    0.563001    0.539519    0.926719    0.869116    800         13.182286   -0.669730   -6.941707   0.679740    48.165277  
[37m[36mINFO[0m[0m 05/30 20:54:33 | 0.560424    0.526919    0.000000    0.858405    0.539686    0.789691    0.560424    0.526919    0.925592    0.859931    1000        16.477858   -0.679493   -7.006134   0.659093    50.420367  
[37m[36mINFO[0m[0m 05/30 20:57:29 | 0.558419    0.531501    0.000000    0.856576    0.540146    0.787629    0.558419    0.531501    0.924464    0.857635    1200        19.773429   -0.686668   -7.054713   0.641345    48.441288  
[37m[36mINFO[0m[0m 05/30 21:00:28 | 0.567583    0.531501    0.000000    0.862749    0.540533    0.795876    0.567583    0.531501    0.927847    0.864524    1400        23.069001   -0.689913   -7.100306   0.663293    45.480539  
[37m[36mINFO[0m[0m 05/30 21:03:33 | 0.560710    0.530355    0.000000    0.865278    0.531192    0.800000    0.560710    0.530355    0.926719    0.869116    1600        26.364573   -0.695603   -7.148104   0.672449    51.190815  
[37m[36mINFO[0m[0m 05/30 21:06:35 | 0.567583    0.530355    0.000000    0.860325    0.538229    0.789691    0.567583    0.530355    0.924464    0.866820    1800        29.660144   -0.701146   -7.192853   0.665886    48.929380  
[37m[36mINFO[0m[0m 05/30 21:09:38 | 0.567010    0.528064    0.000000    0.862275    0.532168    0.787629    0.567010    0.528064    0.931229    0.867968    2000        32.955716   -0.706327   -7.232436   0.667241    48.597384  
[37m[36mINFO[0m[0m 05/30 21:12:35 | 0.562428    0.526919    0.000000    0.862763    0.535878    0.795876    0.562428    0.526919    0.925592    0.866820    2200        36.251287   -0.709938   -7.273959   0.649765    47.434256  
[37m[36mINFO[0m[0m 05/30 21:15:31 | 0.559278    0.529210    0.000000    0.864371    0.538717    0.804124    0.559278    0.529210    0.924464    0.864524    2400        39.546859   -0.714007   -7.308732   0.636934    48.817986  
[37m[36mINFO[0m[0m 05/30 21:18:32 | 0.568729    0.538373    0.000000    0.861452    0.534428    0.789691    0.568729    0.538373    0.927847    0.866820    2600        42.842430   -0.717347   -7.348605   0.661286    49.046254  
[37m[36mINFO[0m[0m 05/30 21:21:31 | 0.564433    0.523482    0.000000    0.862244    0.524753    0.800000    0.564433    0.523482    0.922210    0.864524    2800        46.138002   -0.722306   -7.384743   0.644827    49.991142  
[37m[36mINFO[0m[0m 05/30 21:24:33 | 0.573310    0.525773    0.000000    0.861472    0.527481    0.800000    0.573310    0.525773    0.923337    0.861079    3000        49.433574   -0.727326   -7.423424   0.673300    46.944430  
[37m[36mINFO[0m[0m 05/30 21:27:29 | 0.553265    0.515464    0.000000    0.867340    0.533593    0.806186    0.553265    0.515464    0.926719    0.869116    3200        52.729145   -0.729501   -7.456057   0.645585    47.217951  
[37m[36mINFO[0m[0m 05/30 21:30:30 | 0.566151    0.522337    0.000000    0.866660    0.528503    0.804124    0.566151    0.522337    0.925592    0.870264    3400        56.024717   -0.734566   -7.493885   0.669008    46.671854  
[37m[36mINFO[0m[0m 05/30 21:33:31 | 0.569301    0.526919    0.000000    0.869296    0.517325    0.814433    0.569301    0.526919    0.931229    0.862227    3600        59.320288   -0.735922   -7.519494   0.680783    44.856208  
[37m[36mINFO[0m[0m 05/30 21:36:30 | 0.563574    0.530355    0.000000    0.866937    0.521718    0.806186    0.563574    0.530355    0.930101    0.864524    3800        62.615860   -0.740196   -7.554898   0.683924    41.965712  
[37m[36mINFO[0m[0m 05/30 21:39:34 | 0.568729    0.526919    0.000000    0.867672    0.523778    0.808247    0.568729    0.526919    0.922210    0.872560    4000        65.911432   -0.745397   -7.593733   0.707068    42.557073  
[37m[36mINFO[0m[0m 05/30 21:39:34 | ---
[37m[36mINFO[0m[0m 05/30 21:39:34 | training-domain validation = 56.930%
[37m[36mINFO[0m[0m 05/30 21:39:34 | === Summary ===
[37m[36mINFO[0m[0m 05/30 21:39:34 | Command: prune_all.py OfficeHome_PRUNE1 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 1 --model_save 0 --steps 4000
[37m[36mINFO[0m[0m 05/30 21:39:34 | Unique name: 230530_20-37-41_OfficeHome_PRUNE1
[37m[36mINFO[0m[0m 05/30 21:39:34 | Out path: train_output/OfficeHome/230530_20-37-41_OfficeHome_PRUNE1
[37m[36mINFO[0m[0m 05/30 21:39:34 | Algorithm: MIRO
[37m[36mINFO[0m[0m 05/30 21:39:34 | Dataset: OfficeHome
