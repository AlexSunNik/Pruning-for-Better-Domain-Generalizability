[37m[36mINFO[0m[0m 05/30 20:37:44 | Command :: prune_all.py OfficeHome_PRUNE2 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 2 --model_save 0 --steps 4000
Environment:
	Python: 3.8.5
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.22.4
	PIL: 9.2.0
Args:
	algorithm: MIRO
	checkpoint_freq: None
	configs: []
	data_dir: ../domain_bed
	dataset: OfficeHome
	debug: False
	deterministic: True
	evalmode: fast
	holdout_fraction: 0.2
	model_save: 0
	name: OfficeHome_PRUNE2
	out_dir: train_output/OfficeHome/230530_20-37-44_OfficeHome_PRUNE2
	out_root: train_output/OfficeHome
	prebuild_loader: False
	prune_method: uni
	seed: 0
	show: False
	steps: 4000
	tb_freq: 10
	test_envs: None
	testenv: 2
	trial_seed: 0
	unique_name: 230530_20-37-44_OfficeHome_PRUNE2
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	[36mresnet_dropout: 0.1
	[0mclass_balanced: False
	optimizer: adam
	freeze_bn: True
	pretrained: True
	[36mlr: 6e-06
	[0mbatch_size: 32
	[36mweight_decay: 1e-06
	[0mswad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	[36mld: 0.1
	[0mlr_mult: 10.0
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: Art (#2427)
	env1: Clipart (#4365)
	env2: Product (#4439)
	env3: Real World (#4357)

[37m[36mINFO[0m[0m 05/30 20:37:44 | n_steps = 4000
[37m[36mINFO[0m[0m 05/30 20:37:44 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 05/30 20:37:44 | n_steps is updated to 4000 => 4001 for checkpointing
[37m[36mINFO[0m[0m 05/30 20:37:44 | Target test envs = [[0], [1], [2], [3]]
[37m[36mINFO[0m[0m 05/30 20:37:44 | Prune and finetune for test environment 2
[37m[36mINFO[0m[0m 05/30 20:37:44 | 
[37m[36mINFO[0m[0m 05/30 20:37:44 | Testenv name escaping te_Product -> te_Product
[37m[36mINFO[0m[0m 05/30 20:37:44 | Test envs = [2], name = te_Product
[37m[36mINFO[0m[0m 05/30 20:37:44 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 05/30 20:37:44 | steps-per-epoch for each domain: 60.69, 109.12, 108.94 -> min = 60.69
[37m[36mINFO[0m[0m 05/30 20:38:01 | 23454912.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:38:44 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_out    env2_in     env2_out    env3_out   
[37m[36mINFO[0m[0m 05/30 20:38:44 | 0.791385    0.786922    0.000000    0.829522    0.709223    0.837113    0.792669    0.791385    0.786922    0.858783   
[37m[36mINFO[0m[0m 05/30 20:38:44 | Pruning Completed
[37m[36mINFO[0m[0m 05/30 20:38:44 | 22314688.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:38:44 | # of params = 47153153
[37m[36mINFO[0m[0m 05/30 20:39:27 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_out    env2_in     env2_out    env3_out    step        epoch       loss        reg_loss    step_time   eval_time  
[37m[36mINFO[0m[0m 05/30 20:39:27 | 0.687782    0.671928    0.000000    0.703431    1.216911    0.692784    0.674685    0.687782    0.671928    0.742824    0           0.000000    0.251010    -6.460679   0.723265    42.615190  
[37m[36mINFO[0m[0m 05/30 20:42:21 | 0.768018    0.762120    0.000000    0.799261    0.787430    0.797938    0.767468    0.768018    0.762120    0.832377    200         3.295572    -0.532203   -6.435638   0.645479    44.350651  
[37m[36mINFO[0m[0m 05/30 20:45:21 | 0.768863    0.765502    0.000000    0.801020    0.756003    0.791753    0.775487    0.768863    0.765502    0.835821    400         6.591143    -0.612255   -6.610207   0.686217    42.909278  
[37m[36mINFO[0m[0m 05/30 20:48:26 | 0.777872    0.762120    0.000000    0.810036    0.744659    0.816495    0.772050    0.777872    0.762120    0.841561    600         9.886715    -0.631658   -6.708409   0.707655    43.278000  
[37m[36mINFO[0m[0m 05/30 20:51:31 | 0.776464    0.760992    0.000000    0.805221    0.749449    0.802062    0.776632    0.776464    0.760992    0.836969    800         13.182286   -0.643085   -6.780244   0.693205    46.496362  
[37m[36mINFO[0m[0m 05/30 20:54:32 | 0.775338    0.756483    0.000000    0.812865    0.735627    0.812371    0.778923    0.775338    0.756483    0.847302    1000        16.477858   -0.651095   -6.847750   0.676609    45.767341  
[37m[36mINFO[0m[0m 05/30 20:57:29 | 0.775056    0.765502    0.000000    0.807824    0.748946    0.804124    0.773196    0.775056    0.765502    0.846154    1200        19.773429   -0.660552   -6.900661   0.664226    43.983796  
[37m[36mINFO[0m[0m 05/30 21:00:29 | 0.780687    0.770011    0.000000    0.807513    0.748141    0.802062    0.782360    0.780687    0.770011    0.838117    1400        23.069001   -0.664421   -6.947831   0.668837    46.504999  
[37m[36mINFO[0m[0m 05/30 21:03:33 | 0.777590    0.771139    0.000000    0.811567    0.742872    0.806186    0.781214    0.777590    0.771139    0.847302    1600        26.364573   -0.673940   -6.999547   0.681964    47.273375  
[37m[36mINFO[0m[0m 05/30 21:06:35 | 0.784065    0.786922    0.000000    0.810037    0.735462    0.806186    0.780069    0.784065    0.786922    0.843858    1800        29.660144   -0.677080   -7.044266   0.669200    48.804491  
[37m[36mINFO[0m[0m 05/30 21:09:37 | 0.779279    0.775648    0.000000    0.810881    0.725848    0.804124    0.780069    0.779279    0.775648    0.848450    2000        32.955716   -0.683116   -7.084620   0.672161    47.679883  
[37m[36mINFO[0m[0m 05/30 21:12:34 | 0.782939    0.782413    0.000000    0.809661    0.743155    0.806186    0.772050    0.782939    0.782413    0.850746    2200        36.251287   -0.685107   -7.121996   0.643677    47.534327  
[37m[36mINFO[0m[0m 05/30 21:15:27 | 0.782658    0.775648    0.000000    0.813706    0.723131    0.810309    0.782360    0.782658    0.775648    0.848450    2400        39.546859   -0.690907   -7.163475   0.631536    47.236789  
[37m[36mINFO[0m[0m 05/30 21:18:31 | 0.780968    0.768884    0.000000    0.811113    0.737344    0.797938    0.783505    0.780968    0.768884    0.851894    2600        42.842430   -0.694587   -7.204766   0.676009    48.153612  
[37m[36mINFO[0m[0m 05/30 21:21:31 | 0.780968    0.771139    0.000000    0.807590    0.741823    0.810309    0.773196    0.780968    0.771139    0.839265    2800        46.138002   -0.701432   -7.240489   0.660279    47.757343  
[37m[36mINFO[0m[0m 05/30 21:24:31 | 0.781250    0.774521    0.000000    0.808892    0.741283    0.806186    0.776632    0.781250    0.774521    0.843858    3000        49.433574   -0.702787   -7.277860   0.655187    49.001272  
[37m[36mINFO[0m[0m 05/30 21:27:28 | 0.776745    0.784667    0.000000    0.807365    0.735438    0.806186    0.772050    0.776745    0.784667    0.843858    3200        52.729145   -0.707526   -7.313998   0.658921    45.830237  
[37m[36mINFO[0m[0m 05/30 21:30:28 | 0.785755    0.795941    0.000000    0.809500    0.722841    0.810309    0.777778    0.785755    0.795941    0.840413    3400        56.024717   -0.711560   -7.349439   0.675297    45.099819  
[37m[36mINFO[0m[0m 05/30 21:33:32 | 0.779842    0.784667    0.000000    0.811796    0.729330    0.810309    0.777778    0.779842    0.784667    0.847302    3600        59.320288   -0.714185   -7.376735   0.688018    45.742276  
[37m[36mINFO[0m[0m 05/30 21:36:32 | 0.778716    0.780158    0.000000    0.816148    0.724846    0.816495    0.785796    0.778716    0.780158    0.846154    3800        62.615860   -0.718480   -7.411218   0.701523    39.664287  
[37m[36mINFO[0m[0m 05/30 21:39:33 | 0.784065    0.771139    0.000000    0.809887    0.729962    0.810309    0.772050    0.784065    0.771139    0.847302    4000        65.911432   -0.722559   -7.445665   0.684334    44.744491  
[37m[36mINFO[0m[0m 05/30 21:39:34 | ---
[37m[36mINFO[0m[0m 05/30 21:39:34 | training-domain validation = 78.407%
[37m[36mINFO[0m[0m 05/30 21:39:34 | === Summary ===
[37m[36mINFO[0m[0m 05/30 21:39:34 | Command: prune_all.py OfficeHome_PRUNE2 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 2 --model_save 0 --steps 4000
[37m[36mINFO[0m[0m 05/30 21:39:34 | Unique name: 230530_20-37-44_OfficeHome_PRUNE2
[37m[36mINFO[0m[0m 05/30 21:39:34 | Out path: train_output/OfficeHome/230530_20-37-44_OfficeHome_PRUNE2
[37m[36mINFO[0m[0m 05/30 21:39:34 | Algorithm: MIRO
[37m[36mINFO[0m[0m 05/30 21:39:34 | Dataset: OfficeHome
