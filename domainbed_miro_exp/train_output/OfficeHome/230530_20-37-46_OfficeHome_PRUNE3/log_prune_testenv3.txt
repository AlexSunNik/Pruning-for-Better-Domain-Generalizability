[37m[36mINFO[0m[0m 05/30 20:37:46 | Command :: prune_all.py OfficeHome_PRUNE3 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 3 --model_save 0 --steps 4000
Environment:
	Python: 3.8.5
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.22.4
	PIL: 9.2.0
Args:
	algorithm: MIRO
	checkpoint_freq: None
	configs: []
	data_dir: ../domain_bed
	dataset: OfficeHome
	debug: False
	deterministic: True
	evalmode: fast
	holdout_fraction: 0.2
	model_save: 0
	name: OfficeHome_PRUNE3
	out_dir: train_output/OfficeHome/230530_20-37-46_OfficeHome_PRUNE3
	out_root: train_output/OfficeHome
	prebuild_loader: False
	prune_method: uni
	seed: 0
	show: False
	steps: 4000
	tb_freq: 10
	test_envs: None
	testenv: 3
	trial_seed: 0
	unique_name: 230530_20-37-46_OfficeHome_PRUNE3
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	[36mresnet_dropout: 0.1
	[0mclass_balanced: False
	optimizer: adam
	freeze_bn: True
	pretrained: True
	[36mlr: 6e-06
	[0mbatch_size: 32
	[36mweight_decay: 1e-06
	[0mswad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	[36mld: 0.1
	[0mlr_mult: 10.0
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: Art (#2427)
	env1: Clipart (#4365)
	env2: Product (#4439)
	env3: Real World (#4357)

[37m[36mINFO[0m[0m 05/30 20:37:46 | n_steps = 4000
[37m[36mINFO[0m[0m 05/30 20:37:46 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 05/30 20:37:46 | n_steps is updated to 4000 => 4001 for checkpointing
[37m[36mINFO[0m[0m 05/30 20:37:46 | Target test envs = [[0], [1], [2], [3]]
[37m[36mINFO[0m[0m 05/30 20:37:46 | Prune and finetune for test environment 3
[37m[36mINFO[0m[0m 05/30 20:37:46 | 
[37m[36mINFO[0m[0m 05/30 20:37:47 | Testenv name escaping te_Real World -> te_Real World
[37m[36mINFO[0m[0m 05/30 20:37:47 | Test envs = [3], name = te_Real World
[37m[36mINFO[0m[0m 05/30 20:37:47 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 05/30 20:37:47 | steps-per-epoch for each domain: 60.69, 109.12, 111.00 -> min = 60.69
[37m[36mINFO[0m[0m 05/30 20:38:01 | 23454912.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:39:22 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_out    env2_out    env3_in     env3_out   
[37m[36mINFO[0m[0m 05/30 20:39:22 | 0.815548    0.832377    0.000000    0.847814    0.666834    0.810309    0.806415    0.926719    0.815548    0.832377   
[37m[36mINFO[0m[0m 05/30 20:39:22 | Pruning Completed
[37m[36mINFO[0m[0m 05/30 20:39:22 | 22314688.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:39:22 | # of params = 47153153
[37m[36mINFO[0m[0m 05/30 20:41:27 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_out    env2_out    env3_in     env3_out    step        epoch       loss        reg_loss    step_time   eval_time  
[37m[36mINFO[0m[0m 05/30 20:41:27 | 0.748422    0.737084    0.000000    0.752109    1.028300    0.692784    0.704467    0.859076    0.748422    0.737084    0           0.000000    -0.061115   -6.521297   0.747024    123.743104 
[37m[36mINFO[0m[0m 05/30 20:45:16 | 0.800344    0.791045    0.000000    0.820737    0.720615    0.771134    0.784651    0.906426    0.800344    0.791045    200         3.295572    -0.554146   -6.431210   0.599734    109.206425 
[37m[36mINFO[0m[0m 05/30 20:48:54 | 0.808090    0.804822    0.000000    0.826975    0.707908    0.777320    0.792669    0.910936    0.808090    0.804822    400         6.591143    -0.614170   -6.591092   0.608227    96.257730  
[37m[36mINFO[0m[0m 05/30 20:52:36 | 0.805508    0.803674    0.000000    0.828460    0.693210    0.767010    0.799542    0.918828    0.805508    0.803674    600         9.886715    -0.630257   -6.685288   0.609727    100.527930 
[37m[36mINFO[0m[0m 05/30 20:56:37 | 0.810671    0.804822    0.000000    0.824748    0.693502    0.775258    0.785796    0.913191    0.810671    0.804822    800         13.182286   -0.639819   -6.750440   0.605100    119.427938 
[37m[36mINFO[0m[0m 05/30 21:00:23 | 0.814974    0.809414    0.000000    0.832602    0.685096    0.789691    0.792669    0.915445    0.814974    0.809414    1000        16.477858   -0.650844   -6.815498   0.599941    106.446833 
[37m[36mINFO[0m[0m 05/30 21:03:59 | 0.816122    0.817451    0.000000    0.832513    0.682548    0.781443    0.798396    0.917700    0.816122    0.817451    1200        19.773429   -0.656219   -6.862759   0.603074    94.926952  
[37m[36mINFO[0m[0m 05/30 21:07:36 | 0.815261    0.812859    0.000000    0.832754    0.682631    0.785567    0.797251    0.915445    0.815261    0.812859    1400        23.069001   -0.663378   -6.910874   0.604163    95.909459  
[37m[36mINFO[0m[0m 05/30 21:11:26 | 0.811532    0.815155    0.000000    0.833558    0.687201    0.783505    0.794960    0.922210    0.811532    0.815155    1600        26.364573   -0.667483   -6.958273   0.596433    111.269307 
[37m[36mINFO[0m[0m 05/30 21:15:12 | 0.810958    0.812859    0.000000    0.830076    0.692237    0.785567    0.788087    0.916573    0.810958    0.812859    1800        29.660144   -0.671643   -6.999129   0.604194    104.811854 
[37m[36mINFO[0m[0m 05/30 21:18:52 | 0.815835    0.817451    0.000000    0.836319    0.676679    0.791753    0.797251    0.919955    0.815835    0.817451    2000        32.955716   -0.678292   -7.039910   0.598838    100.101957 
[37m[36mINFO[0m[0m 05/30 21:22:38 | 0.818990    0.823192    0.000000    0.833693    0.682026    0.779381    0.796105    0.925592    0.818990    0.823192    2200        36.251287   -0.681219   -7.079766   0.606074    104.526881 
[37m[36mINFO[0m[0m 05/30 21:26:34 | 0.818703    0.823192    0.000000    0.835867    0.683806    0.793814    0.794960    0.918828    0.818703    0.823192    2400        39.546859   -0.685629   -7.117476   0.594933    116.907852 
[37m[36mINFO[0m[0m 05/30 21:30:13 | 0.812679    0.818599    0.000000    0.835721    0.679818    0.797938    0.791523    0.917700    0.812679    0.818599    2600        42.842430   -0.691952   -7.155206   0.602844    98.198478  
[37m[36mINFO[0m[0m 05/30 21:33:46 | 0.818130    0.827784    0.000000    0.836536    0.675153    0.785567    0.801833    0.922210    0.818130    0.827784    2800        46.138002   -0.694672   -7.191331   0.606983    91.924756  
[37m[36mINFO[0m[0m 05/30 21:37:26 | 0.813827    0.815155    0.000000    0.837776    0.681016    0.793814    0.800687    0.918828    0.813827    0.815155    3000        49.433574   -0.698453   -7.227803   0.614254    97.522717  
[37m[36mINFO[0m[0m 05/30 21:40:15 | 0.819277    0.819747    0.000000    0.836090    0.685478    0.787629    0.800687    0.919955    0.819277    0.819747    3200        52.729145   -0.703393   -7.265073   0.604629    47.785596  
[37m[36mINFO[0m[0m 05/30 21:42:43 | 0.816982    0.822044    0.000000    0.835968    0.676427    0.802062    0.791523    0.914318    0.816982    0.822044    3400        56.024717   -0.706641   -7.294150   0.555067    36.990921  
[37m[36mINFO[0m[0m 05/30 21:45:13 | 0.820138    0.820896    0.000000    0.837648    0.672505    0.797938    0.800687    0.914318    0.820138    0.820896    3600        59.320288   -0.709263   -7.328171   0.555690    38.391307  
[37m[36mINFO[0m[0m 05/30 21:47:41 | 0.820425    0.824340    0.000000    0.837788    0.677880    0.793814    0.802978    0.916573    0.820425    0.824340    3800        62.615860   -0.712153   -7.362118   0.553950    37.938028  
[37m[36mINFO[0m[0m 05/30 21:50:11 | 0.820138    0.833525    0.000000    0.838775    0.682169    0.797938    0.800687    0.917700    0.820138    0.833525    4000        65.911432   -0.716621   -7.398637   0.553008    39.161744  
[37m[36mINFO[0m[0m 05/30 21:50:11 | ---
[37m[36mINFO[0m[0m 05/30 21:50:11 | training-domain validation = 82.014%
[37m[36mINFO[0m[0m 05/30 21:50:11 | === Summary ===
[37m[36mINFO[0m[0m 05/30 21:50:11 | Command: prune_all.py OfficeHome_PRUNE3 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 3 --model_save 0 --steps 4000
[37m[36mINFO[0m[0m 05/30 21:50:11 | Unique name: 230530_20-37-46_OfficeHome_PRUNE3
[37m[36mINFO[0m[0m 05/30 21:50:11 | Out path: train_output/OfficeHome/230530_20-37-46_OfficeHome_PRUNE3
[37m[36mINFO[0m[0m 05/30 21:50:11 | Algorithm: MIRO
[37m[36mINFO[0m[0m 05/30 21:50:11 | Dataset: OfficeHome
