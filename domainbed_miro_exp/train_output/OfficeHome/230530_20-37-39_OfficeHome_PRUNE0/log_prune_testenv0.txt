[37m[36mINFO[0m[0m 05/30 20:37:39 | Command :: prune_all.py OfficeHome_PRUNE0 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 0 --model_save 0 --steps 4000
Environment:
	Python: 3.8.5
	PyTorch: 1.13.1+cu117
	Torchvision: 0.14.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.22.4
	PIL: 9.2.0
Args:
	algorithm: MIRO
	checkpoint_freq: None
	configs: []
	data_dir: ../domain_bed
	dataset: OfficeHome
	debug: False
	deterministic: True
	evalmode: fast
	holdout_fraction: 0.2
	model_save: 0
	name: OfficeHome_PRUNE0
	out_dir: train_output/OfficeHome/230530_20-37-39_OfficeHome_PRUNE0
	out_root: train_output/OfficeHome
	prebuild_loader: False
	prune_method: uni
	seed: 0
	show: False
	steps: 4000
	tb_freq: 10
	test_envs: None
	testenv: 0
	trial_seed: 0
	unique_name: 230530_20-37-39_OfficeHome_PRUNE0
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	[36mresnet_dropout: 0.1
	[0mclass_balanced: False
	optimizer: adam
	freeze_bn: True
	pretrained: True
	[36mlr: 6e-06
	[0mbatch_size: 32
	[36mweight_decay: 1e-06
	[0mswad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	model: resnet50
	feat_layers: stem_block
	[36mld: 0.1
	[0mlr_mult: 10.0
Dataset:
	[OfficeHome] #envs=4, #classes=65
	env0: Art (#2427)
	env1: Clipart (#4365)
	env2: Product (#4439)
	env3: Real World (#4357)

[37m[36mINFO[0m[0m 05/30 20:37:39 | n_steps = 4000
[37m[36mINFO[0m[0m 05/30 20:37:39 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 05/30 20:37:39 | n_steps is updated to 4000 => 4001 for checkpointing
[37m[36mINFO[0m[0m 05/30 20:37:39 | Target test envs = [[0], [1], [2], [3]]
[37m[36mINFO[0m[0m 05/30 20:37:39 | Prune and finetune for test environment 0
[37m[36mINFO[0m[0m 05/30 20:37:39 | 
[37m[36mINFO[0m[0m 05/30 20:37:40 | Testenv name escaping te_Art -> te_Art
[37m[36mINFO[0m[0m 05/30 20:37:40 | Test envs = [0], name = te_Art
[37m[36mINFO[0m[0m 05/30 20:37:40 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 05/30 20:37:40 | steps-per-epoch for each domain: 109.12, 111.00, 108.94 -> min = 108.94
[37m[36mINFO[0m[0m 05/30 20:37:59 | 23454912.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:38:42 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_out    env2_out    env3_out   
[37m[36mINFO[0m[0m 05/30 20:38:42 | 0.669928    0.705155    0.000000    0.860198    0.588696    0.669928    0.705155    0.800687    0.918828    0.861079   
[37m[36mINFO[0m[0m 05/30 20:38:42 | Pruning Completed
[37m[36mINFO[0m[0m 05/30 20:38:42 | 22314688.0 parameters out of 23454912


[37m[36mINFO[0m[0m 05/30 20:38:42 | # of params = 47153153
[37m[36mINFO[0m[0m 05/30 20:39:25 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_out    env2_out    env3_out    step        epoch       loss        reg_loss    step_time   eval_time  
[37m[36mINFO[0m[0m 05/30 20:39:25 | 0.579815    0.608247    0.000000    0.781849    0.883365    0.579815    0.608247    0.713631    0.850056    0.781860    0           0.000000    -0.230592   -6.424721   0.806559    42.600173  
[37m[36mINFO[0m[0m 05/30 20:42:31 | 0.649846    0.711340    0.000000    0.847985    0.628321    0.649846    0.711340    0.784651    0.915445    0.843858    200         1.835915    -0.553526   -6.467881   0.691657    46.750058  
[37m[36mINFO[0m[0m 05/30 20:45:38 | 0.651390    0.711340    0.000000    0.851053    0.624045    0.651390    0.711340    0.784651    0.914318    0.854191    400         3.671830    -0.614356   -6.616097   0.689883    49.354737  
[37m[36mINFO[0m[0m 05/30 20:48:46 | 0.660144    0.707216    0.000000    0.849913    0.616233    0.660144    0.707216    0.783505    0.913191    0.853042    600         5.507745    -0.630393   -6.692315   0.698527    48.805274  
[37m[36mINFO[0m[0m 05/30 20:51:56 | 0.656025    0.711340    0.000000    0.848794    0.608206    0.656025    0.711340    0.781214    0.908681    0.856487    800         7.343660    -0.638438   -6.760536   0.700619    49.425580  
[37m[36mINFO[0m[0m 05/30 20:55:01 | 0.655510    0.690722    0.000000    0.846521    0.626245    0.655510    0.690722    0.777778    0.905299    0.856487    1000        9.179575    -0.648219   -6.812759   0.673248    50.455561  
[37m[36mINFO[0m[0m 05/30 20:58:05 | 0.659629    0.713402    0.000000    0.853734    0.603861    0.659629    0.713402    0.790378    0.913191    0.857635    1200        11.015491   -0.654721   -6.857287   0.641152    55.106598  
[37m[36mINFO[0m[0m 05/30 21:01:16 | 0.665294    0.698969    0.000000    0.850313    0.613380    0.665294    0.698969    0.778923    0.910936    0.861079    1400        12.851406   -0.660789   -6.903530   0.665177    58.621731  
[37m[36mINFO[0m[0m 05/30 21:04:31 | 0.671473    0.713402    0.000000    0.848772    0.605573    0.671473    0.713402    0.783505    0.912063    0.850746    1600        14.687321   -0.664553   -6.949680   0.666510    61.827494  
[37m[36mINFO[0m[0m 05/30 21:07:46 | 0.671473    0.711340    0.000000    0.851051    0.604857    0.671473    0.711340    0.786942    0.914318    0.851894    1800        16.523236   -0.671615   -6.992489   0.650238    64.363137  
[37m[36mINFO[0m[0m 05/30 21:10:56 | 0.667353    0.707216    0.000000    0.854859    0.608408    0.667353    0.707216    0.784651    0.917700    0.862227    2000        18.359151   -0.675945   -7.030316   0.647494    60.126806  
[37m[36mINFO[0m[0m 05/30 21:14:07 | 0.666838    0.711340    0.000000    0.849525    0.611007    0.666838    0.711340    0.781214    0.914318    0.853042    2200        20.195066   -0.680484   -7.066325   0.638520    63.663645  
[37m[36mINFO[0m[0m 05/30 21:17:21 | 0.668898    0.707216    0.000000    0.851088    0.605339    0.668898    0.707216    0.792669    0.907554    0.853042    2400        22.030981   -0.683819   -7.103636   0.658111    62.506806  
[37m[36mINFO[0m[0m 05/30 21:20:35 | 0.667353    0.701031    0.000000    0.854484    0.600830    0.667353    0.701031    0.792669    0.915445    0.855339    2600        23.866896   -0.687015   -7.140087   0.634563    67.092492  
[37m[36mINFO[0m[0m 05/30 21:23:43 | 0.677137    0.721649    0.000000    0.853366    0.596789    0.677137    0.721649    0.790378    0.910936    0.858783    2800        25.702811   -0.693488   -7.178294   0.621815    63.703372  
[37m[36mINFO[0m[0m 05/30 21:26:49 | 0.669413    0.707216    0.000000    0.851421    0.608005    0.669413    0.707216    0.785796    0.916573    0.851894    3000        27.538726   -0.697430   -7.215709   0.628529    60.119220  
[37m[36mINFO[0m[0m 05/30 21:30:01 | 0.671988    0.713402    0.000000    0.859048    0.589843    0.671988    0.713402    0.793814    0.919955    0.863375    3200        29.374641   -0.700767   -7.250569   0.670458    57.856979  
[37m[36mINFO[0m[0m 05/30 21:33:13 | 0.681771    0.731959    0.000000    0.857135    0.597582    0.681771    0.731959    0.793814    0.919955    0.857635    3400        31.210557   -0.704749   -7.283962   0.697994    52.046001  
[37m[36mINFO[0m[0m 05/30 21:36:30 | 0.668383    0.711340    0.000000    0.854844    0.596438    0.668383    0.711340    0.786942    0.919955    0.857635    3600        33.046472   -0.708814   -7.319336   0.721896    52.410949  
[37m[36mINFO[0m[0m 05/30 21:39:33 | 0.675592    0.717526    0.000000    0.855215    0.604380    0.675592    0.717526    0.792669    0.921082    0.851894    3800        34.882387   -0.712850   -7.351500   0.686565    46.053787  
[37m[36mINFO[0m[0m 05/30 21:41:46 | 0.670443    0.711340    0.000000    0.850299    0.602415    0.670443    0.711340    0.788087    0.912063    0.850746    4000        36.718302   -0.714594   -7.383859   0.542019    24.415900  
[37m[36mINFO[0m[0m 05/30 21:41:46 | ---
[37m[36mINFO[0m[0m 05/30 21:41:46 | training-domain validation = 68.177%
[37m[36mINFO[0m[0m 05/30 21:41:46 | === Summary ===
[37m[36mINFO[0m[0m 05/30 21:41:46 | Command: prune_all.py OfficeHome_PRUNE0 --data_dir ../domain_bed/ --algorithm MIRO --dataset OfficeHome --lr 6e-6 --resnet_dropout 0.1 --weight_decay 1e-6 --ld 0.1 --testenv 0 --model_save 0 --steps 4000
[37m[36mINFO[0m[0m 05/30 21:41:46 | Unique name: 230530_20-37-39_OfficeHome_PRUNE0
[37m[36mINFO[0m[0m 05/30 21:41:46 | Out path: train_output/OfficeHome/230530_20-37-39_OfficeHome_PRUNE0
[37m[36mINFO[0m[0m 05/30 21:41:46 | Algorithm: MIRO
[37m[36mINFO[0m[0m 05/30 21:41:46 | Dataset: OfficeHome
